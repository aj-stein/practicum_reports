\documentclass{jdf}

\begin{document}
Section: PUBP-6727
\title{Mutual Monitoring in the Cloud \\ Progress Report 3}
\author{Alexander Stein}

\maketitle
\thispagestyle{fancy}


\section*{Problem Statement}

Cloud computing infrastructure is essentially ubiquitous, but adoption is not without challenges. Cloud service providers must cater to customers in regulated sectors, complying with cybersecurity frameworks that create high barriers to entry. One barrier is ongoing evaluation of the provider's cybersecurity posture, often resulting in centralized bureaucracies. FedRAMP oversees a prominent example of such a program, the Continuous Monitoring Program, which is emblematic of these barriers. This program requires hundreds of cloud service providers to contract with one of thirty reputable auditor firms. The providers work with the auditors to send security scans and updated security control documentation for FedRAMP-authorized services monthly to FedRAMP reviewers, in some cases for the largest cloud infrastructures in the world. All three parties collaborate in meetings, emails, and a wiki, forming a unique multi-party bureaucracy that both secures and bottlenecks the government's acquisition of modern cloud services.

Are these bureaucracies an optimal solution, or a last resort that fails to keep pace with cloud technology as it proliferates and evolves? If they are a last resort, is there a better way?

\section*{Solution Statement}

I will use this research to design and evaluate an alternative to centralized continuous monitoring, mutual monitoring. The foundation of mutual monitoring will be federated data services, known in other security use cases as \hyperlink{https://transparency.dev}{transparency services}. The positives and negatives of FedRAMP's continuous monitoring model will inform its design. Operating such services can change the economics, and thereby the behavior, of cloud service providers and their customers. A new architecture will incentivize auditors to sell value-add analytics via these federated data services, potentially obsoleting centralized authorities for continuous monitoring like FedRAMP.

\section*{Completed Tasks (Last 2 Weeks)}

\begin{enumerate}
    \item FedRAMP began to archive some older parts of their modernization forums, which is an important input to my critical analysis of FedRAMP. I therefore had to urgently write export scripts to export the all this (public domain) content to my repositories as to not potentially lose a vital primary resource for my research.
    \item I completed a draft of the architecture specification. I am sending it subject-matter experts advising me for feedback and further revisions.
    \item I continued development of of the core transparency service and utility classes shared with Relying Party clients, but development is further behind schedule.
    \item I had to re-review to additional specifications related to core functionality of transparency services, specifically techniques for detached signatures and digital signing algorithms.
        \begin{itemize}
            \item \hyperlink{https://datatracker.ietf.org/doc/draft-ietf-scitt-scrapi/}{SCITT Reference API}
            \item \hyperlink{https://datatracker.ietf.org/doc/draft-ietf-cose-merkle-tree-proofs/}{Merkle Tree Proofs}
            \item \hyperlink{https://datatracker.ietf.org/doc/draft-ietf-cose-hash-envelope/}{COSE Hash Envelope}
        \end{itemize}
    \item I outlined my critical analysis of FedRAMP.
    \item I drafted the critical analysis of FedRAMP, intending to complete draft for subject-matter expert review in the beginning of Week 7.
    \item I evaluated development of Monte Carlo simulations in Python for cost and duration of FedRAMP continuous monitoring and other FedRAMP processes for consideration in my evaluation plan below.
    \item I completed more desk research of FedRAMP documentation and industry analyst commentary to fill knowledge gaps for the critical analysis draft.
\end{enumerate}

\section*{Tasks for the Next Project Report}

In the next two weeks, I will focus on the following goals. I have sorted them in order of priority. I will have shift focus to complete and start milestones previously scheduled for weeks three and four due to the troubleshooting described above.

\begin{enumerate}
    \item Ramp up development of submission API for cloud service providers and external third-party auditors.
    \item Design the quantitative cloud security measurement framework to implement into transparency service statements.
    \item Recruit participants to interview as part of my revised strategy documented in my evaluation plan.
\end{enumerate}

\section*{Questions or issues I'm having}

\subsection*{Deliverables and Scope}

\begin{enumerate}
    \item I am having more difficulty in translating upstream specifications and reference code for supply chain and certificate transparency services to my cloud security monitoring use cases than I had originally anticipated. I will continue to work on the prototype during and after the practicum, but should I focus the paper and final presentation on a walkthrough of the specification in lieu of incomplete code? Show both anyway?
\end{enumerate}

\subsection*{Evaluation and Measurement}

\begin{enumerate}
    \item Per the professor's feedback during office hours, I have opted for interviewing those stakeholders for which my problem space and solution is relevant. Qualitative analysis of their comments in interviews will replace different quantitative sampling methods of social media the professors recommended against. To that end, how structured and consistent do the interviews have to be as an important input to the project evaluation?
\end{enumerate}

\section*{Methodology Paragraph Summary}

For this project, I will use multiple methods to implement an alternative architecture for monitoring cloud services and modeling its potential impact. To start, I will use a quantitative and qualitative analysis of the current shortcomings and gaps for the current FedRAMP Continuous Monitoring Program. This will be the primary example of centralized continuous monitoring for which I design my mutual monitoring model for comparison. For qualitative analysis, I can perform textual analysis and sentiment analysis. I will leverage academic research, industry analysis, and a new primary source: FedRAMP's web-based forums for \hyperlink{https://www.fedramp.gov/20x/working-groups/}{the 20x reform initiative and its community working groups}. In these forums, stakeholders discuss their praise and criticism of current centralized processes and plans for future ones, often summarizing their pain points highly relevant to designing an alternative process. In addition, I will use publicly available information from FedRAMP and industry analysis to quantify the burden of the current FedRAMP Continuous Monitoring and its manual workflow. As I build a prototype based on my architecture, I will design several use cases to estimate the cost and resource efficiency to compare those costs against the estimated costs for my solution. In addition to these methods, I will use advisors familiar with FedRAMP from different stakeholder perspectives to validate information or analysis where these methods prove lacking and leave gaps.

\section*{Timeline}

\begin{xltabular}{\textwidth}{|l|X|l|}
    % \caption{Timeline for Mutual Monitoring Project} 
    % \label{tab:timeline} \\
    \hline \multicolumn{1}{|c|}{\textbf{Week \#}} & \multicolumn{1}{c|}{\textbf{Description of Task}} & \multicolumn{1}{c|}{\textbf{Status}} \\
    \endfirsthead
    \hline
    % \multicolumn{3}{c}%
    % {\tablename\ \thetable{} -- continued from previous page} \\
    % \hline \multicolumn{1}{|c|}{\textbf{Week \#}} & \multicolumn{1}{c|}{\textbf{Description of Task}} & \multicolumn{1}{c|}{\textbf{Status}} \\ \hline 
    % \endhead
    % \hline \multicolumn{3}{|r|}{{Continued on next page}} \\ \hline
    % \endfoot    
    % \hline
    % \endlastfoot
    W5 (June 9-15) & Implement data service client to submit to submission API instances. & Continued \\
    \hline
    W5 & Complete data service internals and submission API. & Continued \\
    \hline
    W5 & Complete outline of FedRAMP ConMon critical analysis. & Continued \\
    \hline
    W5 & Complete FedRAMP critical analysis document. & Deferred \\
    \hline
    W6 (June 16-22) & Complete data service client to submit to submission API instances. & Deferred \\
    \hline
    W6 & Design MVP continuous monitoring use cases and quantitative measurements. & Deferred \\
    \hline
    W6 & Implement data service client to submit to submission API instances. & Pending \\
    \hline
    W6 & Complete data service internals and submission API. & Continued \\
    \hline
    W6 & Build data export tool for complete, offline archive of 20x forums. & Continued \\
    \hline
    W7 (June 23-29) & Complete FedRAMP critical analysis document. & In Progress \\
    \hline
    W7 & Complete implementation of data service client to submit to submission API instances. & Pending \\
    \hline    
    W7 & Implement MVP continuous monitoring use cases in API quantitative processing module. & Pending \\
    \hline
    W7 & Design MVP continuous monitoring use cases and quantitative measurements. & Deferred \\
    \hline
    W7 & Finalize architecture specification with advisors' reviews. & Pending \\
    \hline
    W7 & Implement continuous monitoring quantitative processing module for API. & Deferred \\
    \hline
    W7 & Recruit stakeholders to interview for project evaluation. & Pending \\
    \hline          
    W8 (June 30 - July 6) & Start prototype deployment to cloud service tenants for testing. & Pending \\
    \hline
    W8 & Design MVP continuous monitoring use cases and quantitative measurements. & Pending \\
    \hline
    W8 & Implement continuous monitoring quantitative processing module for API. & Pending \\
    \hline    
    W8 & Interview stakeholders for project evaluation. & Pending \\
    \hline  
    W9 (July 7-13) & Complete prototype deployment to cloud service tenants for testing. & Pending \\
    \hline
    W9 & Interview stakeholders for project evaluation. & Pending \\
    \hline
\end{xltabular}

\section*{Evaluation}

\input{evaluation_plan}

\section*{Report Outline}

[Include an outline of your final report by Progress Report 4. This may expand as you finalize the report.]

\nocite{*}
\bibliographystyle{apacite}
%  Relatives path work because you initialize top-level practicum repo
%  so the paths are consistent. Clone this repo and initialize the
%  submodules and it will work.
%  https://github.com/aj-stein/practicum.git
\bibliography{../references.bib}

\section*{\centering{Appendix}}

%  Relatives path work because you initialize top-level practicum repo
%  so the paths are consistent. Clone this repo and initialize the
%  submodules and it will work.
%  https://github.com/aj-stein/practicum.git
\includepdf[pages=-]{../prototype/build/architecture.pdf}

\end{document}
