\subsection*{Summary}

The project, as \hyperlink{https://github.com/aj-stein/practicum_proposal/blob/5238ba70dd8736320400ee6907b3fcfdd8ae672b/paper.pdf}{detailed in the intial proposal}, examines the many challenges to effective multi-party security monitoring of cloud service providers and designing a solution based on two areas of work. The first area of work is an analysis of best-in-class contemporary techniques for multi-party cloud security monitoring, typified by FedRAMP's administration of their \hyperlink{https://web.archive.org/web/20250616221039/https://www.fedramp.gov/assets/resources/documents/CSP_Continuous_Monitoring_Performance_Management_Guide.pdf}{Continuous Monitoring Program}. The second area of work, informed by the first, is a specification and prototype for a novel architecture for multi-party security monitoring of cloud service providers, addressing challenges and shortcomings identified from the first work area.

To evaluate the solution, I plan to use a multi-disciplinary approach to assess the project's final deliverables, identifying benefits to the proposed solutions; confirm and discover limitations to the solution; and propose future areas of work. I categorize this multi-disciplinary approach into qualitative and quantitative methods, which I describe in more detail below.

\subsubsection*{Quantitative Methods}

Evaluating this project will include the quantitative methods below.

\begin{enumerate}
  \item Model the range of costs for continuous monitoring process, data access, and submission for FedRAMP's current requirements.
  \item Model the range of duration for processes related to continuous monitoring activities for FedRAMP's current requirements.
  \item Model and estimate the equivalent processes in the proposed mutual monitoring architecture.
\end{enumerate}

\subsubsection*{Qualitative Methods}

Evaluating this project will include the qualitative methods below.

\begin{enumerate}
  \item Identify challenges and obstacles to current FedRAMP continuous monitoring processes through resources including. but not limited to:
  \begin{itemize}
    \item literature review of multi-party security monitoring of cloud service providers, as FedRAMP and other regulatory frameworks implement it;
    \item sentiment analysis FedRAMP's official forum for its 20x modernization program, in which stakeholders often critique current processes.
  \end{itemize}
  \item Use data from 1 to identify features and use cases of the mutual monitoring architecture to address identified challenges with a qualitative analysis of their positive or negative impact.
  \item Interview stakeholders with different roles in FedRAMP authorizations and continuous monitoring. Participants will answer questions regarding the relevance and impact of challenges identified and benefits of the mutual monitoring solution's features to their work. The final report will summarize qualitative analysis of their answers to model how a mutual monitoring ecosystem will benefit the persona the stakeholder represents in the ecosystem.
\end{enumerate}


\subsection*{Initial Results}

\subsubsection*{Qualitative Results}

Although I am still in the process of scheduling interviews with industry experts and have not completed a significant number of interviews, I have completed coding of all written comments by participants in the FedRAMP 20x Working Groups for the current modernization of its program. These comments are a vital primary source representing the official positions of FedRAMP staff and perspectives from personas of other stakeholders in FedRAMP processes past and present. I have done qualitative analysis to identify twelve themes that represent higher-level requirements for key FedRAMP uses cases. As I will document in my final paper, my mutual monitoring architecture and use of transparency services can effectively address ten of these twelve higher level requirements from FedRAMP, cloud service providers, auditors, and agency customers. These twelve requirements are currently unmet or poorly implemented, as documented by participant feedback. Addressing over 80\% of the higher level requirements, often based in precise critical feedback from FedRAMP stakeholders in the public record, is a strong indicator that future prototypes of this architecture can positively impact the FedRAMP continuous monitoring processes with a radically different approach.

\subsubsection*{Quantitative Results}

As a full analysis and model for development and operations of continuous monitoring infrastructure is pending, preliminary analysis indicates mutual monitoring with a transparency service architecture can significantly improve the submission, measurement, and verification steps of FedRAMP processes. My proposed architecture obsoletes a formal authorization process before continuous monitoring in favor of assessment via continuous monitoring and metrics derived from a rolling window period. Updated analysis indicates that the cumulative average number of days for all FedRAMP authorizations, from beginning to end, is 381 days. Despite significant improvements in the last three months by FedRAMP staff, the improvements offset a previous cumulative average in the months prior of over 390 days. With regards to operation, recording assessments through quantitative measurement for only automation-friendly properties of a service can reduce a 381 day delay to days or weeks. The precise improvement depends on industry risk appetite for a real-world deployment, in which FedRAMP and industry accept the longest minimal rolling window duration for inventory and configuration monitoring use cases. By analyzing transparency services for other use cases, aside from the rolling window of measurements to be assessed, CSP reporting, auditor analysis, and metrics reporting can occurs in minutes. As current continuous monitoring requires monthly synchronous meetings for each authorized cloud service, this improvement is a significant increase in speed and efficiency. As for development, further quantitative study is required, but initial reports from respondents to my inquiries indicates similar implementations are possible for one senior engineer in fourteen days. Other companies have implemented similar architectures in months, once the specifications for those use cases were completed.
